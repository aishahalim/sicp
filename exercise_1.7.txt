Exercise 1.7.  The good-enough? test used in computing square roots will not be very effective for finding the square roots of very small numbers. Also, in real computers, arithmetic operations are almost always performed with limited precision. This makes our test inadequate for very large numbers. Explain these statements, with examples showing how the test fails for small and large numbers. An alternative strategy for implementing good-enough? is to watch how guess changes from one iteration to the next and to stop when the change is a very small fraction of the guess. Design a square-root procedure that uses this kind of end test. Does this work better for small and large numbers?

sqrt x = y 
sqr ( sqrt x ) = sqr y
x = y^2

if x is really small, then y has to be y times smaller than itself. Meaning, y's precision needs to increase more and more. If you look at the graph between x and y for x [0,1]:
  y 
  ^
1 |--[--.
  | [   |
  |[____|_>x
0 |     1  

you see the precision getting unweildly in the perspective of computing when subtracting each miniscule guess n number of times before reaching the desired threshold

if x is really large, y guesses need to average out much more frequently to approach the threshold -- it takes longer to reach
